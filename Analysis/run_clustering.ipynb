{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.2.0-rc1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"Tensorflow version : {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.ops import sparse_ops\n",
    "import tensorflow.keras.backend as K\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "assert tf.__version__=='2.2.0-rc1'\n",
    "# assert tf.test.is_gpu_available()\n",
    "K.clear_session()\n",
    "%load_ext tensorboard\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.clustering import cluster_maker, cluster_splitter, scalar_features, tf_serialize_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'eventId': tf.io.FixedLenFeature([1], tf.int64, default_value=0),\n",
    "    'image': tf.io.FixedLenFeature([3], tf.string, default_value=[\"\",]*3)\n",
    "}\n",
    "\n",
    "feature_shape = {\n",
    "    'eventId': tf.TensorShape([1,]),\n",
    "    'image': tf.TensorShape([568, 568, 2])\n",
    "}\n",
    "\n",
    "def parser_fn(proto):\n",
    "    serialized = tf.io.parse_single_example(proto, feature_description)\n",
    "    deserialized = {k: (tf.sparse.to_dense(sparse_ops.deserialize_sparse(v, K.floatx()))\n",
    "                        if k != 'eventId' else v) for k,v in serialized.items()}\n",
    "    [deserialized[k].set_shape(feature_shape[k]) for k in deserialized.keys()]\n",
    "    x = deserialized['image']\n",
    "    x = tf.expand_dims(x, axis=0)\n",
    "    x = K.pool2d(x, pool_size=(2, 2), strides=(2, 2), pool_mode='avg')\n",
    "    # sum instead of avg\n",
    "#     x = 4.*x\n",
    "    deserialized['image'] = tf.squeeze(x)\n",
    "    deserialized['S_image'] = deserialized['image'][:,:,0]\n",
    "    deserialized['C_image'] = deserialized['image'][:,:,1]\n",
    "    \n",
    "    # set EM633\n",
    "    deserialized['tseed'] = tf.constant(6., tf.float32)\n",
    "    deserialized['tneighbour'] = tf.constant(3., tf.float32)\n",
    "    deserialized['tcell'] = tf.constant(3., tf.float32)\n",
    "    deserialized['tenergy'] = tf.constant(1000., tf.float32)\n",
    "    deserialized['tlocmax'] = tf.constant(500., tf.float32)\n",
    "    deserialized['tnum'] = tf.constant(3, tf.int32)\n",
    "    \n",
    "    return deserialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {eventId: (1,), image: (284, 284, 2), S_image: (284, 284), C_image: (284, 284), tseed: (), tneighbour: (), tcell: (), tenergy: (), tlocmax: (), tnum: ()}, types: {eventId: tf.int64, image: tf.float32, S_image: tf.float32, C_image: tf.float32, tseed: tf.float32, tneighbour: tf.float32, tcell: tf.float32, tenergy: tf.float32, tlocmax: tf.float32, tnum: tf.int32}>\n",
      "<MapDataset shapes: {eventId: (1,), image: (284, 284, 2), S_image: (284, 284), C_image: (284, 284), tseed: (), tneighbour: (), tcell: (), tenergy: (), tlocmax: (), tnum: (), proto: (None, 3), cluster: (None, 4), feature: (None, 5)}, types: {eventId: tf.int64, image: tf.float32, S_image: tf.float32, C_image: tf.float32, tseed: tf.float32, tneighbour: tf.float32, tcell: tf.float32, tenergy: tf.float32, tlocmax: tf.float32, tnum: tf.int32, proto: tf.int64, cluster: tf.float32, feature: tf.float32}>\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = ''\n",
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 10\n",
    "\n",
    "filename = [os.path.join(DATA_DIR, 'B4.tfrecord')]\n",
    "dataset = tf.data.TFRecordDataset(filename, compression_type='GZIP', buffer_size=BUFFER_SIZE)\n",
    "dataset = dataset.map(parser_fn)\n",
    "print(dataset)\n",
    "clusters_dataset = dataset.take(10).map(lambda x: cluster_maker(x, im='S_image'))\n",
    "clusters_dataset = clusters_dataset.map(lambda x: cluster_splitter(x, im='S_image'))\n",
    "features_dataset = clusters_dataset.map(scalar_features)\n",
    "serialized_features_dataset = features_dataset.map(tf_serialize_example)\n",
    "print(features_dataset)\n",
    "# print(clusters_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locmax [[19 126 150]]\n",
      "seedlist [[20 126 150]]\n",
      "locmax []\n",
      "seedlist []\n",
      "locmax []\n",
      "seedlist []\n",
      "locmax []\n",
      "seedlist []\n",
      "locmax []\n",
      "seedlist []\n",
      "locmax []\n",
      "seedlist []\n",
      "locmax []\n",
      "seedlist []\n",
      "locmax []\n",
      "seedlist []\n",
      "locmax []\n",
      "seedlist []\n",
      "locmax []\n",
      "seedlist []\n"
     ]
    }
   ],
   "source": [
    "filename = 'test123.tfrecord'\n",
    "writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "writer.write(serialized_features_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"S_hot\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.11785701662302017\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_rad_mean\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 2.3386428356170654\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_sum\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 6445.4306640625\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"cluster_comi\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 126.17872619628906\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"cluster_comj\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 150.4558563232422\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"eventId\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"S_hot\"\n",
      "    value {\n",
      "      float_list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_rad_mean\"\n",
      "    value {\n",
      "      float_list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_sum\"\n",
      "    value {\n",
      "      float_list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"cluster_comi\"\n",
      "    value {\n",
      "      float_list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"cluster_comj\"\n",
      "    value {\n",
      "      float_list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"eventId\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filenames = [filename]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "for raw_record in raw_dataset.take(2):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locmax [[19 126 150]]\n",
      "seedlist [[20 126 150]]\n",
      "locmax []\n",
      "seedlist []\n",
      "locmax []\n",
      "seedlist []\n",
      "locmax []\n",
      "seedlist []\n"
     ]
    }
   ],
   "source": [
    "for output in clusters_dataset.take(4):\n",
    "    output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (0,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-8191f9936942>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mhk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mhtot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/releases/LCG_96python3/numpy/1.16.4/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# Must reshape to a contiguous 2D array for this to work...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0morig_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f{i}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (0,newaxis)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c1\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "from array import array\n",
    "C = output['cluster'].numpy()\n",
    "\n",
    "h = ROOT.TH2F(\"\",\"\", 284, 0., 284., 284, 0., 284.)\n",
    "c = ROOT.TCanvas(\"c1\",\"c1\", 800, 400)\n",
    "c.Divide(2)\n",
    "ROOT.gStyle.SetOptStat(0)\n",
    "palette = [ROOT.kRed, ROOT.kGreen, ROOT.kYellow, ROOT.kBlue]\n",
    "for l in range(2):\n",
    "    c.cd(l+1)\n",
    "    ROOT.gPad.SetLeftMargin(0.05)\n",
    "    ROOT.gPad.SetBottomMargin(0.05)\n",
    "    ROOT.gPad.SetRightMargin(0.15)\n",
    "    ROOT.gPad.SetTopMargin(0.15)\n",
    "#     Cl = C[C[...,3]==l]\n",
    "    Cl = C\n",
    "#     idx = np.array([1,2,4])\n",
    "    idx = np.array([1,2,3])\n",
    "    hk = []\n",
    "    u = np.unique(Cl[:,0], axis=0).astype(int)\n",
    "    htot = h.Clone()\n",
    "    arr = array('d',[0.5])\n",
    "    for k in range(len(u)):\n",
    "        for i,j,x in Cl[Cl[...,0]==u[k]][:,idx]:\n",
    "#         for i,j,x in Cl[:,idx]:\n",
    "\n",
    "            hk.append(h.Clone())\n",
    "            hk[k].Fill(j,i,x)\n",
    "            htot.Add(hk[k])\n",
    "    htot.DrawCopy(\"COLZ\")\n",
    "\n",
    "    for k in range(len(u)):\n",
    "        hk[k].SetLineColor(palette[k])\n",
    "        hk[k].SetLineWidth(1)\n",
    "        hk[k].SetContour(1, arr)\n",
    "        hk[k].DrawCopy(\"cont3 list same\")\n",
    "\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
