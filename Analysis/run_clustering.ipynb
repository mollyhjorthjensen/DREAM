{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.1.0-dlenv_tfe\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"Tensorflow version : {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import sparse_ops\n",
    "import tensorflow.keras.backend as K\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "# assert tf.test.is_gpu_available()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.1.0-dlenv_tfe\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.clustering import make_clusters, extract_features, tf_serialize_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'eventId': tf.io.FixedLenFeature([1], tf.int64, default_value=0),\n",
    "    'image': tf.io.FixedLenFeature([3], tf.string, default_value=[\"\",]*3)\n",
    "}\n",
    "\n",
    "feature_shape = {\n",
    "    'eventId': tf.TensorShape([1,]),\n",
    "    'image': tf.TensorShape([568, 568, 2])\n",
    "}\n",
    "\n",
    "def parser_fn(proto):\n",
    "    serialized = tf.io.parse_single_example(proto, feature_description)\n",
    "    deserialized = {k: (tf.sparse.to_dense(sparse_ops.deserialize_sparse(v, K.floatx()))\n",
    "                        if k != 'eventId' else v) for k,v in serialized.items()}\n",
    "    [deserialized[k].set_shape(feature_shape[k]) for k in deserialized.keys()]\n",
    "    x = deserialized['image']\n",
    "    x = tf.expand_dims(x, axis=0)\n",
    "    x = K.pool2d(x, pool_size=(2, 2), strides=(2, 2), pool_mode='avg')\n",
    "    # sum instead of avg\n",
    "    x = 4.*x\n",
    "    deserialized['image'] = tf.squeeze(x)\n",
    "    deserialized['S_image'] = deserialized['image'][:,:,0]\n",
    "    deserialized['C_image'] = deserialized['image'][:,:,1]\n",
    "    \n",
    "    # set EM633\n",
    "    deserialized['tseed'] = tf.constant(6., tf.float32)\n",
    "    deserialized['tneighbour'] = tf.constant(3., tf.float32)\n",
    "    deserialized['tcell'] = tf.constant(3., tf.float32)\n",
    "    deserialized['tenergy'] = tf.constant(1000., tf.float32)\n",
    "    deserialized['tlocmax'] = tf.constant(500., tf.float32)\n",
    "    deserialized['tnum'] = tf.constant(3, tf.int32)\n",
    "    \n",
    "    return deserialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function make_clusters at 0x7fe034833440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'NoneType' object has no attribute 'add_ordinary_node'\n",
      "WARNING: AutoGraph could not transform <function make_clusters at 0x7fe034833440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'NoneType' object has no attribute 'add_ordinary_node'\n",
      "WARNING:tensorflow:AutoGraph could not transform <function extract_features at 0x7fe0348334d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'NoneType' object has no attribute 'add_ordinary_node'\n",
      "WARNING: AutoGraph could not transform <function extract_features at 0x7fe0348334d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'NoneType' object has no attribute 'add_ordinary_node'\n",
      "WARNING:tensorflow:AutoGraph could not transform <function tf_serialize_example at 0x7fe0348337a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'NoneType' object has no attribute 'add_ordinary_node'\n",
      "WARNING: AutoGraph could not transform <function tf_serialize_example at 0x7fe0348337a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'NoneType' object has no attribute 'add_ordinary_node'\n"
     ]
    }
   ],
   "source": [
    "# DATA_DIR = '/groups/hep/mojen/repositories/DREAM/Run/final_run/tauolaevts/5000'\n",
    "DATA_DIR = '/home/jupyter/DREAM'\n",
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 10\n",
    "\n",
    "filename = [os.path.join(DATA_DIR, 'filtered.tfrecord')]\n",
    "dataset = tf.data.TFRecordDataset(filename, compression_type='GZIP', buffer_size=BUFFER_SIZE)\n",
    "dataset = dataset.map(parser_fn)\n",
    "clusters_dataset = dataset.take(10).map(make_clusters)\n",
    "features_dataset = clusters_dataset.map(extract_features)\n",
    "S_serialized_features_dataset = features_dataset.map(lambda x: tf_serialize_example(x, 'S'))\n",
    "C_serialized_features_dataset = features_dataset.map(lambda x: tf_serialize_example(x, 'C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.1 s ± 95.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "writer = tf.data.experimental.TFRecordWriter(os.path.join(DATA_DIR, 'S_cluster.tfrecord'))\n",
    "writer.write(S_serialized_features_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.data.experimental.TFRecordWriter(os.path.join(DATA_DIR, 'C_cluster.tfrecord'))\n",
    "writer.write(C_serialized_features_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"S_comi\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 126.0400619506836\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_comj\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 150.54531860351562\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_hot\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.11042886972427368\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_rad_mean\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 2.8370704650878906\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_sum\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 27515.96484375\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"eventId\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"S_comi\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 147.32266235351562\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_comj\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 162.519287109375\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_hot\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.16552889347076416\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_rad_mean\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 3.3551764488220215\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_sum\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 2722.92529296875\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"eventId\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"S_comi\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 133.1097869873047\n",
      "        value: 179.5121612548828\n",
      "        value: 185.58004760742188\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_comj\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 166.61509704589844\n",
      "        value: 135.18466186523438\n",
      "        value: 110.19221496582031\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_hot\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.10425625741481781\n",
      "        value: 0.1854388266801834\n",
      "        value: 0.08693371713161469\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_rad_mean\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 4.1946001052856445\n",
      "        value: 1.8687078952789307\n",
      "        value: 2.2862706184387207\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_sum\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 4964.0205078125\n",
      "        value: 2338.27197265625\n",
      "        value: 7369.46875\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"eventId\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 2\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"S_comi\"\n",
      "    value {\n",
      "      float_list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_comj\"\n",
      "    value {\n",
      "      float_list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_hot\"\n",
      "    value {\n",
      "      float_list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_rad_mean\"\n",
      "    value {\n",
      "      float_list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"S_sum\"\n",
      "    value {\n",
      "      float_list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"eventId\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 3\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filenames = [filename]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "for raw_record in raw_dataset.take(4):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0b577d33ce8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclusters_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mplot_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_output' is not defined"
     ]
    }
   ],
   "source": [
    "for output in clusters_dataset.take(10):\n",
    "    plot_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from array import array\n",
    "\n",
    "def plot_output(output):\n",
    "    h = ROOT.TH2F(\"\",\"\", 284, 0., 284., 284, 0., 284.)\n",
    "    c = ROOT.TCanvas(\"c1\",\"c1\", 800, 400)\n",
    "    c.Divide(2)\n",
    "    ROOT.gStyle.SetOptStat(0)\n",
    "    palette = [ROOT.kRed, ROOT.kGreen, ROOT.kYellow, ROOT.kBlue, ROOT.kRed, ROOT.kGreen, ROOT.kYellow, ROOT.kBlue]\n",
    "    for l,X in enumerate(['S', 'C']):\n",
    "        c.cd(l+1)\n",
    "        ROOT.gPad.SetLeftMargin(0.05)\n",
    "        ROOT.gPad.SetBottomMargin(0.05)\n",
    "        ROOT.gPad.SetRightMargin(0.15)\n",
    "        ROOT.gPad.SetTopMargin(0.15)\n",
    "        X_image = output[X+'_image']\n",
    "        indices = tf.where(X_image)\n",
    "        values = tf.reshape(tf.gather_nd(X_image, indices), [-1,1])\n",
    "        X_image = tf.concat([tf.cast(indices, values.dtype), values], axis=1)\n",
    "\n",
    "        htot = h.Clone()\n",
    "        for i,j,x in X_image:\n",
    "            htot.Fill(j,i,x)\n",
    "        htot.DrawCopy(\"COLZ\")\n",
    "\n",
    "        X_cluster = output[X+'_cluster'].numpy()\n",
    "        if X_cluster.size != 0:\n",
    "            hk = []\n",
    "            u = np.unique(X_cluster[:,0], axis=0).astype(int)\n",
    "            arr = array('d',[0.5])\n",
    "            for k in range(len(u)):\n",
    "                for i,j,x in X_cluster[X_cluster[...,0]==u[k]][:,1:]:\n",
    "                    hk.append(h.Clone())\n",
    "                    hk[k].Fill(j,i,x)\n",
    "\n",
    "            for k in range(len(u)):\n",
    "                hk[k].SetLineColor(palette[k])\n",
    "                hk[k].SetLineWidth(1)\n",
    "                hk[k].SetContour(1, arr)\n",
    "                hk[k].DrawCopy(\"cont3 list same\")\n",
    "\n",
    "    c.SaveAs(\"cluster\"+str(output['eventId'][0].numpy())+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
